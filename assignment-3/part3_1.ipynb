{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(n, p, rng, *, sparsity=0.95, SNR=2.0, beta_scale=5.0, sd=1):\n",
    "    \"\"\"Simulate data for Project 3, Part 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of samples\n",
    "    p : int\n",
    "        Number of features\n",
    "    rng : numpy.random.Generator\n",
    "        Random number generator (e.g. from numpy.random.default_rng)\n",
    "    sparsity : float in (0, 1)\n",
    "        Percentage of zero elements in simulated regression coefficients\n",
    "    SNR : positive float\n",
    "        Signal-to-noise ratio (see explanation above)\n",
    "    beta_scale : float\n",
    "        Scaling for the coefficient to make sure they are large\n",
    "    sd : float\n",
    "        lower values gives more correlations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : n x p numpy.array\n",
    "        Matrix of features\n",
    "    y : n numpy.array\n",
    "        Vector of responses\n",
    "    beta : p numpy.array\n",
    "        Vector of regression coefficients\n",
    "    \"\"\"\n",
    "    x = rng.standard_normal((n, 1))\n",
    "    X = np.tile(x, (1, p)) + rng.normal(loc=0, scale=sd, size=(n, p))\n",
    "    \n",
    "    q = int(np.ceil((1.0 - sparsity) * p))\n",
    "    beta = np.zeros((p,), dtype=float)\n",
    "    beta[:q] = beta_scale * rng.standard_normal(size=(q,))\n",
    "    \n",
    "    sigma = np.sqrt(np.sum(np.square(X @ beta)) / (n - 1)) / SNR\n",
    "\n",
    "    y = X @ beta + sigma * rng.standard_normal(size=(n,))\n",
    "\n",
    "    # Shuffle columns so that non-zero features appear\n",
    "    # not simply in the first (1 - sparsity) * p columns\n",
    "    idx_col = rng.permutation(p)\n",
    "    \n",
    "    return X[:, idx_col], y, beta[idx_col]\n",
    "\n",
    "\n",
    "# returns feature frequency matrix and feature average coefficient value matrix\n",
    "def generate_confidence_data(data, labels, M=50, sample_prop=0.95):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=n_test/(n+n_test), random_state=42)\n",
    "    df = X_train.join(y_train['Class'])\n",
    "    n_classes = labels['Class'].nunique()\n",
    "    n_features = len(data.columns)\n",
    "    F = np.zeros((n_classes, n_features))\n",
    "    I = np.zeros_like(F)\n",
    "    for m in range(M):\n",
    "        sample_data = df.sample(frac=sample_prop, replace=True)\n",
    "        lasso_cv = LassoCV(cv=n_folds).fit(sample_data.iloc[:,0:200], sample_data['Class'])\n",
    "\n",
    "        alpha_min_ij = lasso_cv.alpha_\n",
    "        alpha_min[i,j] += alpha_min_ij\n",
    "        idx_alpha_1se = get_lambda_1se_idx(lasso_cv, n_folds)\n",
    "        alpha_1se_ij = lasso_cv.alphas_[idx_alpha_1se]\n",
    "        alpha_1se[i,j] += alpha_1se_ij\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            for j in range(n_features):\n",
    "                if abs(lasso_cv.coef_[i,j]) > 0:\n",
    "                    F[i,j] += 1\n",
    "        I += lasso_cv.coef_\n",
    "    F = F / M\n",
    "    I = I / M\n",
    "    return F, I\n",
    "\n",
    "\n",
    "def get_lambda_1se_idx(lasso_clf, n_folds):\n",
    "    cv_mean = np.mean(lasso_clf.mse_path_, axis=1)\n",
    "    cv_std = np.std(lasso_clf.mse_path_, axis=1)\n",
    "    idx_min_mean = np.argmin(cv_mean)\n",
    "    idx_alpha = np.where(\n",
    "        (cv_mean <= cv_mean[idx_min_mean] + cv_std[idx_min_mean] / np.sqrt(n_folds)) &\n",
    "        (cv_mean >= cv_mean[idx_min_mean])\n",
    "        )[0][0]\n",
    "    return idx_alpha\n",
    "\n",
    "\n",
    "iter = 1\n",
    "n_test = 1000\n",
    "n_datapoints = np.array([200, 500, 750])\n",
    "sparsity = np.array([0.75, 0.9, 0.95, 0.99])\n",
    "n_folds = 5\n",
    "alpha_min = np.zeros((len(n_datapoints), len(sparsity)), dtype=float)\n",
    "alpha_1se = np.zeros_like(alpha_min)\n",
    "for it in range(iter):\n",
    "    for i,n in enumerate(n_datapoints):\n",
    "        for j,s in enumerate(sparsity):\n",
    "            X, y, beta = simulate_data(n=n+n_test, p=1000,rng=np.random.default_rng(), sparsity=s)\n",
    "            F, I = generate_confidence_data(X, y, M=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8230433a90deedfd204f402afa77435b9f1612df21a8fe919bc9fb2fb8e7ebcb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dat405')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
